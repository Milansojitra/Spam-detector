{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the required data stored in last notebooks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data = {}\n",
    "\n",
    "with open('model_training_data', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['X_train', 'X_test', 'y_train', 'y_test', 'max_words', 'max_sequence', 'legend', 'labels_legend_inverted', 'tokenizer'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Extract data from dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data['X_test']\n",
    "X_train = data['X_train']\n",
    "y_test = data['y_test']\n",
    "y_train = data['y_train']\n",
    "labels_legend_inverted = data['labels_legend_inverted']\n",
    "legend = data['legend']\n",
    "max_sequence = data['max_sequence']\n",
    "max_words = data['max_words']\n",
    "tokenizer = data['tokenizer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calculate the step per epoch and validation size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2582"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_SIZE = len(X_train)\n",
    "TRAINING_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1272"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VALIDATION_SIZE = len(X_test)\n",
    "VALIDATION_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_steps_per_epoch : <function <lambda> at 0x000002122A5F6D30>\n",
      "steps_per_epoch : 21\n",
      "val_steps : 10\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=128\n",
    "\n",
    "# We take the ceiling because we do not drop the remainder of the batch\n",
    "compute_steps_per_epoch = lambda x: int(math.ceil(1. * x / BATCH_SIZE))\n",
    "steps_per_epoch = compute_steps_per_epoch(TRAINING_SIZE)\n",
    "val_steps = compute_steps_per_epoch(VALIDATION_SIZE)\n",
    "\n",
    "print(f'compute_steps_per_epoch : {compute_steps_per_epoch}')\n",
    "print(f'steps_per_epoch : {steps_per_epoch}')\n",
    "print(f'val_steps : {val_steps}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create model blue print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 280, 128)          35840     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 280, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 291,034\n",
      "Trainable params: 291,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "MAX_NUM_WORDS=280\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NUM_WORDS, embed_dim, input_length=X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "21/21 [==============================] - 92s 4s/step - loss: 0.5951 - accuracy: 0.7289 - val_loss: 0.5085 - val_accuracy: 0.7256\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 62s 3s/step - loss: 0.3560 - accuracy: 0.8757 - val_loss: 0.2686 - val_accuracy: 0.8860\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 68s 3s/step - loss: 0.2027 - accuracy: 0.9280 - val_loss: 0.1778 - val_accuracy: 0.9245\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 72s 3s/step - loss: 0.1515 - accuracy: 0.9454 - val_loss: 0.1513 - val_accuracy: 0.9403\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - 89s 4s/step - loss: 0.1118 - accuracy: 0.9613 - val_loss: 0.1425 - val_accuracy: 0.9513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2122c887790>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 5\n",
    "model.fit(X_train, y_train,\n",
    "          validation_data=(X_test, y_test),\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          verbose=1,\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('spam_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2122c887790>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13128425, 0.86871576],\n",
       "       [0.9593877 , 0.04061222],\n",
       "       [0.9846661 , 0.01533389]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  create method to convert the text into token of equal size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token(texts):\n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "    MAX_NUM_WORDS=280\n",
    "    tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    return pad_sequences(sequences, maxlen=MAX_NUM_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11496684, 0.88503313]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(get_token(['get smartphone at lowest price call on 12345678']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9639953 , 0.03600475]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(get_token(['your registration is successfully done']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  load model and check if its working fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "loaded_model = load_model('spam_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11496684, 0.88503313]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(get_token(['get smartphone at lowest price call on 12345678']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9639953 , 0.03600475]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(get_token(['your registration is successfully done']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#     #******************** Happy Ending  ********************#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
